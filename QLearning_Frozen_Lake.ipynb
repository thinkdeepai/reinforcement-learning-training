{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "colab": {
      "name": "QLearning Frozen Lake.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thinkdeepai/reinforcement-learning-training/blob/master/QLearning_Frozen_Lake.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ruwCJBWx8nyy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import gym\n",
        "import random\n",
        "import numpy as np\n",
        "import time, pickle, os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v2XOAonb8ny5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "env = gym.make('FrozenLake8x8-v0')\n",
        "env.reset()\n",
        "epsilon = 0.9\n",
        "total_episodes = 10000\n",
        "max_steps = 100\n",
        "lr_rate = 0.81\n",
        "gamma = 0.96\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CKP6c0iD8ny8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def choose_action(state):\n",
        "    action=0\n",
        "    if np.random.uniform(0, 1) < epsilon:\n",
        "        action = env.action_space.sample()\n",
        "    else:\n",
        "        action = np.argmax(Q[state, :])\n",
        "    return action\n",
        "\n",
        "def learn(state, state2, reward, action):\n",
        "    old_value = Q[state, action]\n",
        "    learned_value = reward + gamma * np.max(Q[state2, :])\n",
        "    Q[state, action] = (1 - lr_rate) * old_value +  lr_rate * learned_value"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UjzAPElj8ny_",
        "colab_type": "code",
        "outputId": "4336220a-80c9-4533-a4df-2846e9597817",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "Q = np.zeros((env.observation_space.n, env.action_space.n))\n",
        "\n",
        "# Start\n",
        "for episode in range(total_episodes):\n",
        "    state = env.reset()\n",
        "    t = 0\n",
        "    while t < max_steps:\n",
        "        #env.render()\n",
        "        action = choose_action(state)  \n",
        "        state2, reward, done, info = env.step(action)  \n",
        "        learn(state, state2, reward, action)\n",
        "        state = state2\n",
        "        t += 1\n",
        "        if done:\n",
        "            break\n",
        "\n",
        "print(Q)\n",
        "\n",
        "\n"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[4.10163191e-01 4.12956050e-01 4.10628555e-01 4.46119664e-01]\n",
            " [4.23884541e-01 4.82630602e-01 4.41168903e-01 4.29746980e-01]\n",
            " [4.98895842e-01 5.04954689e-01 5.04880869e-01 4.95840448e-01]\n",
            " [5.34030038e-01 5.03527036e-01 5.03505184e-01 5.14666937e-01]\n",
            " [5.14324218e-01 5.60441446e-01 5.55636196e-01 5.58567984e-01]\n",
            " [5.48250836e-01 5.80095925e-01 5.61691970e-01 5.77379801e-01]\n",
            " [5.79519254e-01 5.70458075e-01 5.88356628e-01 5.74410376e-01]\n",
            " [6.02391546e-01 5.89187484e-01 5.76978595e-01 5.84700369e-01]\n",
            " [4.07889925e-01 4.12212268e-01 4.27249358e-01 4.35037178e-01]\n",
            " [4.20399553e-01 4.54769874e-01 4.43170447e-01 4.56892842e-01]\n",
            " [4.78177857e-01 4.91074428e-01 4.89158688e-01 4.91054594e-01]\n",
            " [1.82234259e-02 5.08444080e-01 8.34226554e-02 5.16127365e-01]\n",
            " [5.44952667e-01 6.03109335e-01 5.93935556e-01 5.36769779e-01]\n",
            " [6.29386097e-01 5.88755227e-01 5.77435303e-01 5.78890036e-01]\n",
            " [5.84101059e-01 6.60635524e-01 6.23356847e-01 6.16421449e-01]\n",
            " [6.25941114e-01 6.39115124e-01 5.89912249e-01 6.29766313e-01]\n",
            " [3.80608089e-01 3.95007255e-01 4.04765866e-01 4.39089103e-01]\n",
            " [4.38594348e-01 4.31758264e-01 4.59065503e-01 4.09289397e-01]\n",
            " [4.76887896e-01 8.45698676e-02 4.71804060e-01 4.56175301e-01]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            " [5.49778105e-01 6.16449214e-01 5.69760395e-01 5.32394226e-01]\n",
            " [9.50350603e-02 6.52994426e-01 6.80329889e-01 5.31801427e-01]\n",
            " [6.20277084e-01 6.51738068e-01 7.05977954e-01 6.41195135e-01]\n",
            " [6.94612824e-01 6.73779911e-01 6.62064008e-01 6.45872734e-01]\n",
            " [3.73605438e-01 3.86382794e-01 3.63202795e-01 3.95160617e-01]\n",
            " [3.72299785e-01 4.09889654e-01 4.18244971e-01 3.81265246e-01]\n",
            " [4.13889215e-01 5.00945377e-01 4.71360586e-01 4.21410691e-01]\n",
            " [4.06176294e-04 9.97867131e-02 2.60814666e-08 9.62790994e-05]\n",
            " [4.60490310e-01 5.67426983e-01 4.44670542e-01 4.60264694e-01]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            " [2.35922133e-02 7.45192353e-01 6.75727100e-01 1.20230666e-01]\n",
            " [6.97839271e-01 7.76102284e-01 7.18536122e-01 7.15211584e-01]\n",
            " [3.36901495e-01 3.22408729e-01 3.58246898e-01 3.68243756e-01]\n",
            " [3.82667818e-01 3.62008164e-01 1.35442845e-02 3.56626725e-01]\n",
            " [7.15004476e-02 5.57895614e-02 3.41438000e-01 6.32600252e-02]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            " [4.62412176e-01 9.36669334e-02 5.56073163e-01 5.53424275e-01]\n",
            " [1.15021329e-01 5.79340264e-01 6.77119315e-01 1.20464408e-01]\n",
            " [6.88979833e-01 7.72702450e-01 6.54629739e-01 6.89397936e-01]\n",
            " [8.09760000e-01 7.45030051e-01 8.39890248e-01 7.57795918e-01]\n",
            " [3.15611133e-01 1.03314340e-02 2.40192331e-01 3.37860777e-01]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            " [7.47681512e-02 1.79070183e-01 4.09968338e-01 5.51930656e-01]\n",
            " [5.62257826e-01 1.39811239e-02 6.08702954e-01 6.01711601e-01]\n",
            " [5.95878418e-01 6.33898677e-01 5.65088360e-01 5.77031190e-01]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            " [9.27080839e-01 9.29702941e-01 8.20278710e-01 8.27836871e-01]\n",
            " [3.15982886e-01 2.86572749e-01 3.00952693e-01 3.33067958e-01]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            " [3.49524357e-02 1.23302361e-03 6.55453675e-03 3.49406251e-01]\n",
            " [1.45928023e-02 6.93007923e-03 2.56908399e-05 2.18294604e-01]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            " [4.97539467e-01 1.99232095e-04 6.97386896e-01 1.18949219e-01]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            " [7.26910421e-01 9.69491253e-01 9.06209155e-01 1.29948981e-01]\n",
            " [2.42061621e-01 2.51434502e-01 2.84189322e-01 2.35663940e-01]\n",
            " [2.33104132e-01 2.47124453e-01 1.64073590e-01 2.39968787e-01]\n",
            " [1.69692657e-01 1.51726497e-01 2.91651665e-02 2.75010482e-02]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            " [1.32345956e-01 1.37688788e-01 6.56634486e-01 2.41219532e-02]\n",
            " [7.49154084e-01 8.08393632e-01 8.33919757e-01 5.73699107e-01]\n",
            " [7.27426238e-01 8.69438256e-01 1.60249919e-01 6.58916108e-01]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sqcwu3gRmGVR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.save(\"qtable\", Q)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ybe7ywooO-D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OKv3bfV_c7eA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Q = np.load(\"qtable.npy\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aslWnk6XmrNG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"Evaluate agent's performance after Q-learning\"\"\"\n",
        "def evaluate():\n",
        "  total_epochs, total_penalties = 0, 0\n",
        "\n",
        "  for _ in range(total_episodes):\n",
        "      state = env.reset()\n",
        "      epochs, penalties, reward = 0, 0, 0\n",
        "      \n",
        "      done = False\n",
        "      \n",
        "      while not done:\n",
        "          action = np.argmax(Q[state, :])\n",
        "          state, reward, done, info = env.step(action)\n",
        "\n",
        "          if reward < 0:\n",
        "              penalties += 1\n",
        "\n",
        "          epochs += 1\n",
        "\n",
        "      total_penalties += penalties\n",
        "      total_epochs += epochs\n",
        "\n",
        "  print(f\"Results after {total_episodes} episodes:\")\n",
        "  print(f\"Average timesteps per episode: {total_epochs / total_episodes}\")\n",
        "  print(f\"Average penalties per episode: {total_penalties / total_episodes}\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7IYgkfkBo-xP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "c71867a8-8e18-4bba-a873-3ff929c1a8f3"
      },
      "source": [
        "evaluate()"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Results after 10000 episodes:\n",
            "Average timesteps per episode: 47.4936\n",
            "Average penalties per episode: 0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QU6PpqhSps9G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}